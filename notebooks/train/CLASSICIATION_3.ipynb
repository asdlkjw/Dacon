{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16badc31",
   "metadata": {},
   "source": [
    "차량 앞부분만 보고 추론\n",
    "\n",
    "라벨 스무딩 적용\n",
    "\n",
    "좀 더 가벼운 모델 사용하여 시간 절약.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from torchsummaryX import summary\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09010f30",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from setup import get_package_root_path\n",
    "from src.global_exception_handler.v1 import GlobalExceptionHandler\n",
    "from src.webhook.v1 import TeamsWebhook\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pakage_name = os.environ.get(\"PACKAGE_NAME\")\n",
    "root_path = get_package_root_path()\n",
    "\n",
    "# 웹훅 알림 url (없으면 빈 문자열)\n",
    "webhook_url = os.environ.get(\"WEBHOOK_URL\")\n",
    "webhook = TeamsWebhook(webhook_url)\n",
    "\n",
    "# 핸들링할 예외 종류\n",
    "except_tuple = (Exception,)\n",
    "GlobalExceptionHandler(except_tuple=except_tuple, sender=webhook, name=\"dacon_cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    root_path = root_path\n",
    "    # Job Id (보통 파일명과 동일하게)\n",
    "    job_id = \"CLASSICIATION_3\"\n",
    "\n",
    "    # 원천 데이터 경로\n",
    "    data_path = f\"{root_path}/data/cars\"\n",
    "\n",
    "    # 학습의 결과물이 저장될 경로\n",
    "    outputs_path = f\"{root_path}/outputs/{job_id}\"\n",
    "    predict_dir = f\"{outputs_path}/predict\"\n",
    "    recorder_dir = f\"{outputs_path}/recorder\"\n",
    "\n",
    "    learning_late = 0.001\n",
    "    batch_size = 128\n",
    "    epoch = 50\n",
    "    num_classes = 34\n",
    "\n",
    "    classes = [\n",
    "        \"chevrolet_malibu_sedan_2012_2016\",\n",
    "        \"chevrolet_malibu_sedan_2017_2019\",\n",
    "        \"chevrolet_spark_hatchback_2016_2021\",\n",
    "        \"chevrolet_trailblazer_suv_2021_\",\n",
    "        \"chevrolet_trax_suv_2017_2019\",\n",
    "        \"genesis_g80_sedan_2016_2020\",\n",
    "        \"genesis_g80_sedan_2021_\",\n",
    "        \"genesis_gv80_suv_2020_\",\n",
    "        \"hyundai_avante_sedan_2011_2015\",\n",
    "        \"hyundai_avante_sedan_2020_\",\n",
    "        \"hyundai_grandeur_sedan_2011_2016\",\n",
    "        \"hyundai_grandstarex_van_2018_2020\",\n",
    "        \"hyundai_ioniq_hatchback_2016_2019\",\n",
    "        \"hyundai_sonata_sedan_2004_2009\",\n",
    "        \"hyundai_sonata_sedan_2010_2014\",\n",
    "        \"hyundai_sonata_sedan_2019_2020\",\n",
    "        \"kia_carnival_van_2015_2020\",\n",
    "        \"kia_carnival_van_2021_\",\n",
    "        \"kia_k5_sedan_2010_2015\",\n",
    "        \"kia_k5_sedan_2020_\",\n",
    "        \"kia_k7_sedan_2016_2020\",\n",
    "        \"kia_mohave_suv_2020_\",\n",
    "        \"kia_morning_hatchback_2004_2010\",\n",
    "        \"kia_morning_hatchback_2011_2016\",\n",
    "        \"kia_ray_hatchback_2012_2017\",\n",
    "        \"kia_sorrento_suv_2015_2019\",\n",
    "        \"kia_sorrento_suv_2020_\",\n",
    "        \"kia_soul_suv_2014_2018\",\n",
    "        \"kia_sportage_suv_2016_2020\",\n",
    "        \"kia_stonic_suv_2017_2019\",\n",
    "        \"renault_sm3_sedan_2015_2018\",\n",
    "        \"renault_xm3_suv_2020_\",\n",
    "        \"ssangyong_korando_suv_2019_2020\",\n",
    "        \"ssangyong_tivoli_suv_2016_2020\",\n",
    "    ]\n",
    "\n",
    "\n",
    "CFG.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transforms=None, num_classes: int = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def to_categorical(self, y, num_classes):\n",
    "        \"\"\"1-hot encodes a tensor\"\"\"\n",
    "        return np.eye(num_classes, dtype=\"uint8\")[y]\n",
    "\n",
    "    def get_class_weight(self):\n",
    "        return torch.Tensor(\n",
    "            compute_class_weight(\n",
    "                class_weight=\"balanced\", classes=np.unique(self.y), y=self.y\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.X[index]\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = image[int(image.shape[0] / 2) :]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        if self.y is None:  # if test\n",
    "            return image, img_path\n",
    "\n",
    "        # train or valid\n",
    "        label = self.y[index]\n",
    "        if self.num_classes is None:\n",
    "            return image, label, img_path\n",
    "        else:\n",
    "            return image, self.to_categorical(label, self.num_classes), img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a7a17f",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b4067-0669-44a9-bbbc-3065d8cb00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(\n",
    "            224,\n",
    "            224,\n",
    "        ),\n",
    "        A.ShiftScaleRotate(\n",
    "            scale_limit=0.01,\n",
    "            rotate_limit=5,\n",
    "            p=0.9,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "        ),\n",
    "        A.ToGray(p=1),\n",
    "        A.HorizontalFlip(),\n",
    "        A.Equalize(by_channels=False),\n",
    "        A.ElasticTransform(\n",
    "            p=0.5,\n",
    "            alpha=0.20000000298023224,\n",
    "            sigma=3.359999895095825,\n",
    "            alpha_affine=2.009999990463257,\n",
    "            interpolation=1,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "            mask_value=None,\n",
    "            approximate=False,\n",
    "        ),\n",
    "        A.GaussNoise(p=0.5, var_limit=(20, 40)),\n",
    "        A.HueSaturationValue(),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=1),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CoarseDropout(fill_value=255, max_height=12, max_width=12),\n",
    "                A.CoarseDropout(fill_value=128, max_height=12, max_width=12),\n",
    "                A.CoarseDropout(fill_value=0, max_height=12, max_width=12),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224, 224),\n",
    "        A.ToGray(p=1),\n",
    "        A.Equalize(by_channels=False),\n",
    "        # A.GaussianBlur(blur_limit=(3, 21), p=1),\n",
    "        # A.HueSaturationValue(),\n",
    "        # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed83ca14",
   "metadata": {},
   "source": [
    "## Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a223cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "for i, cls in enumerate(range(CFG.num_classes)):\n",
    "    data_path_list = sorted(glob(f\"{CFG.data_path}/{cls}/*.png\"))\n",
    "    data_path_list = np.expand_dims(np.array(data_path_list), 1)\n",
    "\n",
    "    labels = np.ones(data_path_list.shape, dtype=np.uint8) * i\n",
    "\n",
    "    temp = np.concatenate([data_path_list, labels], axis=1)\n",
    "\n",
    "    data = temp if data is None else np.concatenate([data, temp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df = df.astype({\"path\": \"string\", \"label\": \"int\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(range(CFG.num_classes)):\n",
    "    print(f'{cls} : {df[df[\"label\"] == i].shape[0]}')\n",
    "\n",
    "print(\"\")\n",
    "print(f\"전체 : {df.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee6967ed",
   "metadata": {},
   "source": [
    "## Train / Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold_splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "checker = data_fold_splitter.get_n_splits(X=df, y=df[\"label\"])\n",
    "print(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11df848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "def save_pred(saved_path, path, y_true, y_pred, y_prob=None):\n",
    "    os.makedirs(saved_path)\n",
    "\n",
    "    df_data = [path, y_true, y_pred]\n",
    "    df_columns = [\"path\", \"y_true\", \"y_pred\"]\n",
    "\n",
    "    if y_prob != None:\n",
    "        df_data.append(y_prob)\n",
    "        df_columns.append(\"y_prob\")\n",
    "\n",
    "    df = pd.DataFrame(np.array(df_data).T)\n",
    "    df.columns = df_columns\n",
    "\n",
    "    df.to_csv(f\"{saved_path}/pred.csv\", index=False)\n",
    "\n",
    "    ### 임시 confusion_matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.set(rc={\"figure.figsize\": (21, 21)})\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "    _val_score = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    plt.xlabel(f\"Pred / F1-score: {_val_score:.3f}\")\n",
    "    plt.ylabel(\"Real\")\n",
    "\n",
    "    classes_point = list(map(lambda x: x + 0.5, range(CFG.num_classes)))\n",
    "    classes = list(range(CFG.num_classes))\n",
    "    plt.xticks(classes_point, classes)\n",
    "    plt.yticks(classes_point, classes)\n",
    "    plt.savefig(f\"{saved_path}/c_matrix.jpg\")\n",
    "    plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1011ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_eda.v1 import tensor2im\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "def valid(model, criterion, data_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    epoch_paths = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (images, labels, paths) in enumerate(tqdm(data_loader)):\n",
    "            if batch_index % 10 == 0:\n",
    "                temp_img = images[0].detach()\n",
    "                temp_img = tensor2im(temp_img)\n",
    "\n",
    "                cv2.imwrite(f\"{CFG.root_path}/temp/valid_img.jpg\", temp_img)\n",
    "\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            probs = model(images)\n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            probs = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "\n",
    "            preds = np.argmax(probs, 1).astype(np.uint8)\n",
    "            labels = np.argmax(labels, 1).astype(np.uint8)\n",
    "\n",
    "            preds = preds.flatten()\n",
    "            labels = labels.flatten()\n",
    "\n",
    "            y_pred += preds.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            # y_probs += probs.tolist()\n",
    "            epoch_paths += paths\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_score\": val_score,\n",
    "        \"path\": epoch_paths,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cutmix(batch, alpha=1.0):\n",
    "#     data, targets = batch\n",
    "\n",
    "#     indices = torch.randperm(data.size(0))\n",
    "#     shuffled_data = data[indices]\n",
    "#     shuffled_targets = targets[indices]\n",
    "\n",
    "#     lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "#     image_h, image_w = data.shape[2:]\n",
    "#     cx = np.random.uniform(0, image_w)\n",
    "#     cy = np.random.uniform(0, image_h)\n",
    "#     w = image_w * np.sqrt(1 - lam)\n",
    "#     h = image_h * np.sqrt(1 - lam)\n",
    "#     x0 = int(np.round(max(cx - w / 2, 0)))\n",
    "#     x1 = int(np.round(min(cx + w / 2, image_w)))\n",
    "#     y0 = int(np.round(max(cy - h / 2, 0)))\n",
    "#     y1 = int(np.round(min(cy + h / 2, image_h)))\n",
    "\n",
    "#     data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n",
    "#     targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "#     return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.my_loss.v1 import FocalLoss\n",
    "\n",
    "\n",
    "# class CutMixCriterion:\n",
    "#     def __init__(self):\n",
    "#         self.criterion = FocalLoss()\n",
    "\n",
    "#     def __call__(self, preds, targets):\n",
    "#         targets1, targets2, lam = targets\n",
    "#         return lam * self.criterion(preds, targets1) + (1 - lam) * self.criterion(\n",
    "#             preds, targets2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data_loader, device, grad_scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    epoch_paths = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch_index, (images, labels, paths) in enumerate(tqdm(data_loader)):\n",
    "        # images, labels = cutmix(\n",
    "        #     (images, labels),\n",
    "        # )\n",
    "\n",
    "        if batch_index % 10 == 0:\n",
    "            temp_img = images[0].detach()\n",
    "            temp_img = tensor2im(temp_img)\n",
    "\n",
    "            cv2.imwrite(f\"{CFG.root_path}/temp/train_img.jpg\", temp_img)\n",
    "\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        # labels = (\n",
    "        #     labels[0].to(device, dtype=torch.float),\n",
    "        #     labels[1].to(device, dtype=torch.float),\n",
    "        #     labels[2],\n",
    "        # )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if grad_scaler is None:\n",
    "            probs = model(images)\n",
    "            loss = criterion(probs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                probs = model(images)\n",
    "                loss = criterion(probs, labels)\n",
    "\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "\n",
    "        preds = np.argmax(probs, 1).astype(np.uint8)\n",
    "        labels = np.argmax(labels, 1).astype(np.uint8)\n",
    "\n",
    "        preds = preds.flatten()\n",
    "        labels = labels.flatten()\n",
    "\n",
    "        y_pred += preds.tolist()\n",
    "        y_true += labels.tolist()\n",
    "        epoch_paths += paths\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_score\": train_score,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd63b0f",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0caf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes: int) -> nn.Module:\n",
    "    # model = models.efficientnet_b5(weights=models.EfficientNet_B5_Weights.DEFAULT)\n",
    "    # model.classifier = nn.Sequential(nn.Linear(2048, num_classes), nn.Softmax())\n",
    "\n",
    "    # model = timm.models.eva.eva02_large_patch14_448(pretrained=True)\n",
    "    # model.head = nn.Sequential(\n",
    "    #     nn.Linear(1024, 768),\n",
    "    #     nn.BatchNorm1d(768),\n",
    "    #     nn.SiLU(),\n",
    "    #     nn.Dropout(0.2),\n",
    "    #     nn.Linear(768, 384),\n",
    "    #     nn.BatchNorm1d(384),\n",
    "    #     nn.SiLU(),\n",
    "    #     nn.Dropout(0.2),\n",
    "    #     nn.Linear(384, num_classes),\n",
    "    # )\n",
    "\n",
    "    model = models.efficientnet_v2_m(weights=models.EfficientNet_V2_M_Weights.DEFAULT)\n",
    "    model.classifier[1] = nn.Linear(1280, num_classes)\n",
    "\n",
    "    # model = timm.models.convnext.convnext_large_mlp(pretrained=True)\n",
    "    # model.head.fc = nn.Sequential(\n",
    "    #     nn.Linear(1024, 768),\n",
    "    #     nn.LayerNorm(768),\n",
    "    #     nn.SiLU(),\n",
    "    #     nn.Dropout(0.5),\n",
    "    #     nn.Linear(768, num_classes),\n",
    "    # )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# create_model(34)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b230af0",
   "metadata": {},
   "source": [
    "## Snapshot Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    import IPython\n",
    "\n",
    "    notebook_path = IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"]\n",
    "except:\n",
    "    notebook_path = f\"{os.getcwd()}/{CFG.job_id}.ipynb\"\n",
    "\n",
    "\n",
    "os.makedirs(CFG.outputs_path, exist_ok=True)\n",
    "shutil.copy(notebook_path, f\"{CFG.outputs_path}/{os.path.split(notebook_path)[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6358e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.random_seed.v1 import seed_everything, seed_worker\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.recorder.v1 import Recorder\n",
    "from src.my_loss.v1 import FocalLoss\n",
    "from time import time\n",
    "\n",
    "\n",
    "for fold_index, (train_idx, valid_idx) in enumerate(\n",
    "    data_fold_splitter.split(X=df, y=df[\"label\"])\n",
    "):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[valid_idx]\n",
    "\n",
    "    train_dataset = CustomDataset(\n",
    "        train_df[\"path\"].values,\n",
    "        train_df[\"label\"].values,\n",
    "        train_transform,\n",
    "        CFG.num_classes,\n",
    "    )\n",
    "    num_workers = 64\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,  #\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "    )\n",
    "    #\n",
    "    val_dataset = CustomDataset(\n",
    "        val_df[\"path\"].values, val_df[\"label\"].values, val_transform, CFG.num_classes\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "    )\n",
    "    model = create_model(CFG.num_classes)\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG.learning_late)\n",
    "    scheduler = None\n",
    "\n",
    "    recorder = Recorder(\n",
    "        f\"{CFG.recorder_dir}/fold_{fold_index}\", model, optimizer, scheduler\n",
    "    )\n",
    "    print(f\"fold_{fold_index} start\")\n",
    "    if recorder.load_checkpoint(device, \"checkpoint.pt\"):\n",
    "        print(f\"loaded current_epoch: {recorder.current_epoch}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)\n",
    "\n",
    "    best_val_loss = 100\n",
    "    for epoch_index in range(recorder.current_epoch, CFG.epoch):\n",
    "        seed_everything(epoch_index)\n",
    "\n",
    "        train_start_timestamp = time()\n",
    "        train_dict = train(\n",
    "            model, criterion, optimizer, train_loader, device, grad_scaler\n",
    "        )\n",
    "        train_elapsed_time = time() - train_start_timestamp\n",
    "\n",
    "        val_start_timestamp = time()\n",
    "        val_dict = valid(model, criterion, val_loader, device)\n",
    "        val_elapsed_time = time() - val_start_timestamp\n",
    "\n",
    "        recorder.update_row_dict(\"epoch\", epoch_index + 1)\n",
    "\n",
    "        recorder.update_row_dict(\"train_loss\", train_dict[\"train_loss\"])\n",
    "        recorder.update_row_dict(\"val_loss\", val_dict[\"val_loss\"])\n",
    "\n",
    "        recorder.update_row_dict(\"train_score\", train_dict[\"train_score\"])\n",
    "        recorder.update_row_dict(\"val_score\", val_dict[\"val_score\"])\n",
    "\n",
    "        recorder.update_row_dict(\"train_elapsed_time\", train_elapsed_time)\n",
    "        recorder.update_row_dict(\"val_elapsed_time\", val_elapsed_time)\n",
    "        recorder.flush_row_dict(is_print=True)\n",
    "        recorder.save_line_plot([\"loss\"], [0, 1])\n",
    "\n",
    "        save_pred(\n",
    "            f\"{CFG.predict_dir}/fold_{fold_index}/{epoch_index}\",\n",
    "            val_dict[\"path\"],\n",
    "            val_dict[\"y_true\"],\n",
    "            val_dict[\"y_pred\"],\n",
    "        )\n",
    "\n",
    "        if recorder.is_best_score(val_dict[\"val_loss\"], \"min\"):\n",
    "            print(f\"best epoch: {epoch_index + 1}\")\n",
    "            recorder.save_checkpoint(epoch_index, \"best_model.pt\")\n",
    "\n",
    "        recorder.save_checkpoint(epoch_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22d0a58d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80762fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224, 224),\n",
    "        # A.Sharpen(p=1),\n",
    "        # A.RandomBrightnessContrast(p=1),\n",
    "        # A.Equalize(p=1),\n",
    "        A.ToGray(p=1),\n",
    "        A.Equalize(by_channels=False, p=1),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c07821",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "import ttach as tta\n",
    "\n",
    "tta_transforms = tta.Compose(\n",
    "    [\n",
    "        # tta.FiveCrops(150, 150),\n",
    "        # tta.Rotate90(angles=[0, 180]),\n",
    "        # tta.Scale(scales=[1, 2, 4]),\n",
    "        # tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "        tta.HorizontalFlip()\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    model = create_model(CFG.num_classes)\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "\n",
    "    check_point = torch.load(\n",
    "        f\"{CFG.recorder_dir}/fold_{i}/checkpoint.pt\",\n",
    "        map_location=device,\n",
    "    )\n",
    "    print(check_point[\"epoch\"])\n",
    "    print(check_point[\"best_score\"])\n",
    "    model.load_state_dict(check_point[\"model\"])\n",
    "    model.eval()\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "    model_list.append(tta_model)\n",
    "\n",
    "# for i in range(0, 5):\n",
    "#     model = create_model(CFG.num_classes)\n",
    "#     model.to(device)\n",
    "#     model.cuda()\n",
    "\n",
    "#     check_point = torch.load(\n",
    "#         f\"{CFG.recorder_dir}/fold_{i}/checkpoint.pt\",\n",
    "#         map_location=device,\n",
    "#     )\n",
    "#     print(check_point[\"epoch\"])\n",
    "#     print(check_point[\"best_score\"])\n",
    "#     model.load_state_dict(check_point[\"model\"])\n",
    "#     model.eval()\n",
    "#     tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "#     model_list.append(tta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904aac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/*.png\"))\n",
    "# test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/083935946_0.png\"))\n",
    "print(test_list[test_index])\n",
    "print(test_index)\n",
    "img = cv2.cvtColor(cv2.imread(test_list[test_index]), cv2.COLOR_BGR2RGB)\n",
    "test_index += 1\n",
    "with torch.no_grad():\n",
    "    print(img.shape)\n",
    "    img = img[5:-5, 5:-5]\n",
    "    img = img[int(img.shape[0] / 2) :,]\n",
    "    print(img.shape)\n",
    "    test_img = test_transform(image=img)[\"image\"]\n",
    "    test_img = torch.Tensor(test_img).to(device, dtype=torch.float)\n",
    "    test_img = torch.unsqueeze(test_img, 0)\n",
    "    ensemble_probs = None\n",
    "    for tta_model in model_list:\n",
    "        probs = F.softmax(tta_model(test_img), dim=1)\n",
    "        probs = np.round(probs.cpu().detach().numpy(), 3)\n",
    "\n",
    "        if ensemble_probs is None:\n",
    "            ensemble_probs = probs\n",
    "        else:\n",
    "            ensemble_probs = ensemble_probs + probs\n",
    "\n",
    "    ensemble_probs = ensemble_probs / len(model_list)\n",
    "    top1 = np.max(ensemble_probs)\n",
    "    label = np.argmax(ensemble_probs)\n",
    "    print(ensemble_probs)\n",
    "    print(top1)\n",
    "    print(label)\n",
    "    print(CFG.classes[label])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(tensor2im(test_img[0]))\n",
    "    # f\"{test_path}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_submit = pd.read_csv(\"/data/dacon_cars/data/bbox_submit.csv\")\n",
    "filenames = sorted(os.listdir(\"/data/dacon_cars/data/test\"))\n",
    "\n",
    "total_list = []\n",
    "for target in tqdm(iter(filenames)):\n",
    "    car_info_df = bbox_submit[\n",
    "        (bbox_submit[\"file_name\"] == target)\n",
    "        & ((bbox_submit[\"point3_x\"] - bbox_submit[\"point1_x\"]) <= 370)\n",
    "        & ((bbox_submit[\"point3_y\"] - bbox_submit[\"point1_y\"]) <= 441)\n",
    "    ]\n",
    "    # print(one_test)\n",
    "\n",
    "    infer_list = []\n",
    "    for i, car_info in car_info_df.iterrows():\n",
    "        file_name = car_info[\"file_name\"]\n",
    "        img = cv2.cvtColor(\n",
    "            cv2.imread(f\"/data/dacon_cars/data/test/{file_name}\"),\n",
    "            cv2.COLOR_BGR2RGB,\n",
    "        )\n",
    "        pt1x = int(np.round(car_info[\"point1_x\"])) + 5\n",
    "        pt1y = int(np.round(car_info[\"point1_y\"])) + 5\n",
    "        pt2x = int(np.round(car_info[\"point2_x\"])) - 5\n",
    "        pt2y = int(np.round(car_info[\"point2_y\"])) + 5\n",
    "        pt3x = int(np.round(car_info[\"point3_x\"])) - 5\n",
    "        pt3y = int(np.round(car_info[\"point3_y\"])) - 5\n",
    "        pt4x = int(np.round(car_info[\"point4_x\"])) + 5\n",
    "        pt4y = int(np.round(car_info[\"point4_y\"])) - 5\n",
    "\n",
    "        img = img[pt1y:pt3y, pt1x:pt3x]\n",
    "        with torch.no_grad():\n",
    "            img = test_transform(image=img)[\"image\"]\n",
    "            img = torch.Tensor(img).to(device, dtype=torch.float)\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            ensemble_probs = None\n",
    "            for tta_model in model_list:\n",
    "                probs = F.softmax(tta_model(img), dim=1)\n",
    "                probs = np.round(probs.cpu().detach().numpy(), 3)\n",
    "\n",
    "                if ensemble_probs is None:\n",
    "                    ensemble_probs = probs\n",
    "                else:\n",
    "                    ensemble_probs = ensemble_probs + probs\n",
    "\n",
    "            ensemble_probs = ensemble_probs / len(model_list)\n",
    "\n",
    "        class_id = np.argmax(ensemble_probs)\n",
    "        confidence = ensemble_probs[0][class_id]\n",
    "\n",
    "        infer_list.append(\n",
    "            [\n",
    "                file_name,\n",
    "                class_id,\n",
    "                confidence,\n",
    "                pt1x,\n",
    "                pt1y,\n",
    "                pt2x,\n",
    "                pt2y,\n",
    "                pt3x,\n",
    "                pt3y,\n",
    "                pt4x,\n",
    "                pt4y,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    infer_array = np.array(infer_list)\n",
    "    try:\n",
    "        max_confidence_list = infer_array[np.argmax(infer_array.T[2])].tolist()\n",
    "    except:\n",
    "        print(car_info)\n",
    "\n",
    "    total_list.append(max_confidence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e573e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(\n",
    "    total_list,\n",
    "    columns=[\n",
    "        \"file_name\",\n",
    "        \"class_id\",\n",
    "        \"confidence\",\n",
    "        \"point1_x\",\n",
    "        \"point1_y\",\n",
    "        \"point2_x\",\n",
    "        \"point2_y\",\n",
    "        \"point3_x\",\n",
    "        \"point3_y\",\n",
    "        \"point4_x\",\n",
    "        \"point4_y\",\n",
    "    ],\n",
    ")\n",
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"/data/submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f751ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit2_df = pd.read_csv(\"/data/submit2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat(\n",
    "    [submit_df[\"file_name\"], submit_df[\"class_id\"], submit2_df[\"class_id\"]],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# compare_df = pd.merge(\n",
    "#     submit_df[[\"file_name\", \"class_id\"]],\n",
    "#     submit2_df[[\"file_name\", \"class_id\"]],\n",
    "#     how=\"outer\",\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "#     indicator=True,\n",
    "# )\n",
    "\n",
    "compare_df.columns = [\"file_name\", \"class_id1\", \"class_id2\"]\n",
    "# print(compare_df)\n",
    "print(compare_df)\n",
    "compare_df.to_csv(\"/data/temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_df.compare(compare_df, align_axis=1))  # index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
