{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f67c8620",
   "metadata": {},
   "source": [
    "최고 점수 튜닝\n",
    "\n",
    "빠른 학습을 위한 image -> npy 형태로 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from torchsummaryX import summary\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09010f30",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from setup import get_package_root_path\n",
    "from src.global_exception_handler.v1 import GlobalExceptionHandler\n",
    "from src.webhook.v1 import TeamsWebhook\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pakage_name = os.environ.get(\"PACKAGE_NAME\")\n",
    "root_path = get_package_root_path()\n",
    "\n",
    "# 웹훅 알림 url (없으면 빈 문자열)\n",
    "webhook_url = os.environ.get(\"WEBHOOK_URL\")\n",
    "webhook = TeamsWebhook(webhook_url)\n",
    "\n",
    "# 핸들링할 예외 종류\n",
    "except_tuple = (Exception,)\n",
    "GlobalExceptionHandler(except_tuple=except_tuple, sender=webhook, name=\"dacon_cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    root_path = root_path\n",
    "    # Job Id (보통 파일명과 동일하게)\n",
    "    job_id = \"CLASSICIATION_5_submit_special_spark\"\n",
    "\n",
    "    # 원천 데이터 경로\n",
    "    data_path = f\"{root_path}/data/cars\"\n",
    "\n",
    "    # 학습의 결과물이 저장될 경로\n",
    "    outputs_path = f\"{root_path}/outputs/{job_id}\"\n",
    "    predict_dir = f\"{outputs_path}/predict\"\n",
    "    recorder_dir = f\"{outputs_path}/recorder\"\n",
    "\n",
    "    learning_late = 0.0001\n",
    "    batch_size = 32\n",
    "    epoch = 60\n",
    "    num_classes = 34\n",
    "\n",
    "    classes = [\n",
    "        \"chevrolet_malibu_sedan_2012_2016\",\n",
    "        \"chevrolet_malibu_sedan_2017_2019\",\n",
    "        \"chevrolet_spark_hatchback_2016_2021\",\n",
    "        \"chevrolet_trailblazer_suv_2021_\",\n",
    "        \"chevrolet_trax_suv_2017_2019\",\n",
    "        \"genesis_g80_sedan_2016_2020\",\n",
    "        \"genesis_g80_sedan_2021_\",\n",
    "        \"genesis_gv80_suv_2020_\",\n",
    "        \"hyundai_avante_sedan_2011_2015\",\n",
    "        \"hyundai_avante_sedan_2020_\",\n",
    "        \"hyundai_grandeur_sedan_2011_2016\",\n",
    "        \"hyundai_grandstarex_van_2018_2020\",\n",
    "        \"hyundai_ioniq_hatchback_2016_2019\",\n",
    "        \"hyundai_sonata_sedan_2004_2009\",\n",
    "        \"hyundai_sonata_sedan_2010_2014\",\n",
    "        \"hyundai_sonata_sedan_2019_2020\",\n",
    "        \"kia_carnival_van_2015_2020\",\n",
    "        \"kia_carnival_van_2021_\",\n",
    "        \"kia_k5_sedan_2010_2015\",\n",
    "        \"kia_k5_sedan_2020_\",\n",
    "        \"kia_k7_sedan_2016_2020\",\n",
    "        \"kia_mohave_suv_2020_\",\n",
    "        \"kia_morning_hatchback_2004_2010\",\n",
    "        \"kia_morning_hatchback_2011_2016\",\n",
    "        \"kia_ray_hatchback_2012_2017\",\n",
    "        \"kia_sorrento_suv_2015_2019\",\n",
    "        \"kia_sorrento_suv_2020_\",\n",
    "        \"kia_soul_suv_2014_2018\",\n",
    "        \"kia_sportage_suv_2016_2020\",\n",
    "        \"kia_stonic_suv_2017_2019\",\n",
    "        \"renault_sm3_sedan_2015_2018\",\n",
    "        \"renault_xm3_suv_2020_\",\n",
    "        \"ssangyong_korando_suv_2019_2020\",\n",
    "        \"ssangyong_tivoli_suv_2016_2020\",\n",
    "    ]\n",
    "\n",
    "\n",
    "CFG.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transforms=None, num_classes: int = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def to_categorical(self, y, num_classes):\n",
    "        \"\"\"1-hot encodes a tensor\"\"\"\n",
    "        return np.eye(num_classes, dtype=\"uint8\")[y]\n",
    "\n",
    "    def get_class_weight(self):\n",
    "        return torch.Tensor(\n",
    "            compute_class_weight(\n",
    "                class_weight=\"balanced\", classes=np.unique(self.y), y=self.y\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.X[index]\n",
    "        image = cv2.cvtColor(np.load(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        if self.y is None:  # if test\n",
    "            return image, img_path\n",
    "\n",
    "        # train or valid\n",
    "        label = self.y[index]\n",
    "        if self.num_classes is None:\n",
    "            return image, label, img_path\n",
    "        else:\n",
    "            return image, self.to_categorical(label, self.num_classes), img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a7a17f",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b4067-0669-44a9-bbbc-3065d8cb00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(\n",
    "            456,\n",
    "            456,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "        ),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0,\n",
    "            rotate_limit=7,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "            p=0.5,\n",
    "        ),\n",
    "        A.ToGray(p=1),\n",
    "        A.HorizontalFlip(),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.GaussianBlur(blur_limit=(3, 25), p=1),\n",
    "                A.GaussNoise(p=1),\n",
    "                A.Sharpen(p=1),\n",
    "                A.Equalize(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.HueSaturationValue(val_shift_limit=10, p=0.9),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=1),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CoarseDropout(fill_value=255, max_height=25, max_width=25),\n",
    "                A.CoarseDropout(fill_value=128, max_height=25, max_width=25),\n",
    "                A.CoarseDropout(fill_value=0, max_height=25, max_width=25),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(\n",
    "            456,\n",
    "            456,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "        ),\n",
    "        A.ToGray(p=1),\n",
    "        # A.GaussianBlur(blur_limit=(3, 21), p=1),\n",
    "        # A.HueSaturationValue(),\n",
    "        # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed83ca14",
   "metadata": {},
   "source": [
    "## Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a223cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "for i, cls in enumerate(range(CFG.num_classes)):\n",
    "    data_path_list = sorted(glob(f\"{CFG.data_path}/{cls}/*.npy\"))\n",
    "    data_path_list = np.expand_dims(np.array(data_path_list), 1)\n",
    "\n",
    "    labels = np.ones(data_path_list.shape, dtype=np.uint8) * i\n",
    "\n",
    "    temp = np.concatenate([data_path_list, labels], axis=1)\n",
    "\n",
    "    data = temp if data is None else np.concatenate([data, temp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df = df.astype({\"path\": \"string\", \"label\": \"int\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(range(CFG.num_classes)):\n",
    "    print(f'{cls} : {df[df[\"label\"] == i].shape[0]}')\n",
    "\n",
    "print(\"\")\n",
    "print(f\"전체 : {df.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee6967ed",
   "metadata": {},
   "source": [
    "## Train / Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold_splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "checker = data_fold_splitter.get_n_splits(X=df, y=df[\"label\"])\n",
    "print(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11df848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "def save_pred(saved_path, path, y_true, y_pred, y_prob=None):\n",
    "    os.makedirs(saved_path)\n",
    "\n",
    "    df_data = [path, y_true, y_pred]\n",
    "    df_columns = [\"path\", \"y_true\", \"y_pred\"]\n",
    "\n",
    "    if y_prob != None:\n",
    "        df_data.append(y_prob)\n",
    "        df_columns.append(\"y_prob\")\n",
    "\n",
    "    df = pd.DataFrame(np.array(df_data).T)\n",
    "    df.columns = df_columns\n",
    "\n",
    "    df.to_csv(f\"{saved_path}/pred.csv\", index=False)\n",
    "\n",
    "    ### 임시 confusion_matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.set(rc={\"figure.figsize\": (21, 21)})\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "    _val_score = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    plt.xlabel(f\"Pred / F1-score: {_val_score:.3f}\")\n",
    "    plt.ylabel(\"Real\")\n",
    "\n",
    "    classes_point = list(map(lambda x: x + 0.5, range(CFG.num_classes)))\n",
    "    classes = list(range(CFG.num_classes))\n",
    "    plt.xticks(classes_point, classes)\n",
    "    plt.yticks(classes_point, classes)\n",
    "    plt.savefig(f\"{saved_path}/c_matrix.jpg\")\n",
    "    plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1011ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_eda.v1 import tensor2im\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "def valid(model, criterion, data_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    epoch_paths = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (images, labels, paths) in enumerate(tqdm(data_loader)):\n",
    "            if batch_index % 10 == 0:\n",
    "                temp_img = images[0].cpu().detach()\n",
    "                temp_img = tensor2im(temp_img)\n",
    "\n",
    "                cv2.imwrite(f\"{CFG.root_path}/temp/valid_img.jpg\", temp_img)\n",
    "\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            probs = model(images)\n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            probs = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "\n",
    "            preds = np.argmax(probs, 1).astype(np.uint8)\n",
    "            labels = np.argmax(labels, 1).astype(np.uint8)\n",
    "\n",
    "            preds = preds.flatten()\n",
    "            labels = labels.flatten()\n",
    "\n",
    "            y_pred += preds.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            # y_probs += probs.tolist()\n",
    "            epoch_paths += paths\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_score\": val_score,\n",
    "        \"path\": epoch_paths,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data_loader, device, grad_scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    epoch_paths = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch_index, (images, labels, paths) in enumerate(tqdm(data_loader)):\n",
    "        if batch_index % 10 == 0:\n",
    "            temp_img = images[0].detach().cpu()\n",
    "            temp_img = tensor2im(temp_img)\n",
    "\n",
    "            cv2.imwrite(f\"{CFG.root_path}/temp/train_img.jpg\", temp_img)\n",
    "\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if grad_scaler is None:\n",
    "            probs = model(images)\n",
    "            loss = criterion(probs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                probs = model(images)\n",
    "                loss = criterion(probs, labels)\n",
    "\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "\n",
    "        preds = np.argmax(probs, 1).astype(np.uint8)\n",
    "        labels = np.argmax(labels, 1).astype(np.uint8)\n",
    "\n",
    "        preds = preds.flatten()\n",
    "        labels = labels.flatten()\n",
    "\n",
    "        y_pred += preds.tolist()\n",
    "        y_true += labels.tolist()\n",
    "        epoch_paths += paths\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_score\": train_score,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd63b0f",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0caf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes: int) -> nn.Module:\n",
    "    # model = models.efficientnet_b5(weights=models.EfficientNet_B5_Weights.DEFAULT)\n",
    "    # model.classifier = nn.Sequential(nn.Linear(2048, num_classes), nn.Softmax())\n",
    "\n",
    "    # model = timm.models.eva.eva02_base_patch14_448(pretrained=True)\n",
    "    # model.head = nn.Sequential(\n",
    "    #     nn.Linear(768, ),\n",
    "    #     nn.BatchNorm1d(),\n",
    "    #     nn.GELU(),\n",
    "    #     nn.Dropout(0.5),\n",
    "    #     nn.Linear(768, num_classes),\n",
    "    # )\n",
    "\n",
    "    # model = models.convnext_large(weights=models.ConvNeXt_Large_Weights.DEFAULT)\n",
    "    # model.classifier[2] = nn.Sequential(\n",
    "    #     nn.Linear(1536, 1024),\n",
    "    #     nn.LayerNorm(1024),\n",
    "    #     nn.SiLU(),\n",
    "    #     nn.Dropout1d(0.5),\n",
    "    #     nn.Linear(1024, num_classes),\n",
    "    # )\n",
    "\n",
    "    model = timm.models.convnext.convnext_large(pretrained=True)\n",
    "    model.head.fc = nn.Sequential(\n",
    "        nn.Linear(1536, 768),\n",
    "        nn.LayerNorm(768),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(768, num_classes),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "create_model(34)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b230af0",
   "metadata": {},
   "source": [
    "## Snapshot Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    import IPython\n",
    "\n",
    "    notebook_path = IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"]\n",
    "except:\n",
    "    notebook_path = f\"{os.getcwd()}/{CFG.job_id}.ipynb\"\n",
    "\n",
    "\n",
    "os.makedirs(CFG.outputs_path, exist_ok=True)\n",
    "shutil.copy(notebook_path, f\"{CFG.outputs_path}/{os.path.split(notebook_path)[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6358e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.random_seed.v1 import seed_everything, seed_worker\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.recorder.v1 import Recorder\n",
    "from time import time\n",
    "\n",
    "\n",
    "for fold_index, (train_idx, valid_idx) in enumerate(\n",
    "    data_fold_splitter.split(X=df, y=df[\"label\"])\n",
    "):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[valid_idx]\n",
    "\n",
    "    train_dataset = CustomDataset(\n",
    "        train_df[\"path\"].values,\n",
    "        train_df[\"label\"].values,\n",
    "        train_transform,\n",
    "        CFG.num_classes,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=16,  #\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "    )\n",
    "    #\n",
    "    val_dataset = CustomDataset(\n",
    "        val_df[\"path\"].values, val_df[\"label\"].values, val_transform, CFG.num_classes\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=16,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "    )\n",
    "    model = create_model(CFG.num_classes)\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG.learning_late)\n",
    "    scheduler = None\n",
    "\n",
    "    recorder = Recorder(\n",
    "        f\"{CFG.recorder_dir}/fold_{fold_index}\", model, optimizer, scheduler\n",
    "    )\n",
    "    print(f\"fold_{fold_index} start\")\n",
    "    if recorder.load_checkpoint(device, \"checkpoint.pt\"):\n",
    "        print(f\"loaded current_epoch: {recorder.current_epoch}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = 100\n",
    "    for epoch_index in range(recorder.current_epoch, CFG.epoch):\n",
    "        seed_everything(epoch_index)\n",
    "\n",
    "        train_start_timestamp = time()\n",
    "        train_dict = train(\n",
    "            model, criterion, optimizer, train_loader, device, grad_scaler\n",
    "        )\n",
    "        train_elapsed_time = time() - train_start_timestamp\n",
    "\n",
    "        val_start_timestamp = time()\n",
    "        val_dict = valid(model, criterion, val_loader, device)\n",
    "        val_elapsed_time = time() - val_start_timestamp\n",
    "\n",
    "        recorder.update_row_dict(\"epoch\", epoch_index + 1)\n",
    "\n",
    "        recorder.update_row_dict(\"train_loss\", train_dict[\"train_loss\"])\n",
    "        recorder.update_row_dict(\"val_loss\", val_dict[\"val_loss\"])\n",
    "\n",
    "        recorder.update_row_dict(\"train_score\", train_dict[\"train_score\"])\n",
    "        recorder.update_row_dict(\"val_score\", val_dict[\"val_score\"])\n",
    "\n",
    "        recorder.update_row_dict(\"train_elapsed_time\", train_elapsed_time)\n",
    "        recorder.update_row_dict(\"val_elapsed_time\", val_elapsed_time)\n",
    "        recorder.flush_row_dict(is_print=True)\n",
    "        recorder.save_line_plot([\"loss\"], [0, 0.1])\n",
    "\n",
    "        save_pred(\n",
    "            f\"{CFG.predict_dir}/fold_{fold_index}/{epoch_index+1}\",\n",
    "            val_dict[\"path\"],\n",
    "            val_dict[\"y_true\"],\n",
    "            val_dict[\"y_pred\"],\n",
    "        )\n",
    "\n",
    "        if recorder.is_best_score(val_dict[\"val_loss\"], \"min\"):\n",
    "            print(f\"best epoch: {epoch_index + 1}\")\n",
    "            recorder.save_checkpoint(epoch_index, \"best_model.pt\")\n",
    "\n",
    "        recorder.save_checkpoint(epoch_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22d0a58d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smaller_box_with_iou_threshold(box1, box2, iou_threshold=0.1):\n",
    "    # box1 = (x1, y1, x2, y2)\n",
    "    # box2 = (x1, y1, x2, y2)\n",
    "\n",
    "    # 상자1의 좌표 추출\n",
    "    x1_box1, y1_box1, x2_box1, y2_box1 = box1\n",
    "    # 상자2의 좌표 추출\n",
    "    x1_box2, y1_box2, x2_box2, y2_box2 = box2\n",
    "\n",
    "    # 상자1의 면적 계산\n",
    "    area_box1 = (x2_box1 - x1_box1) * (y2_box1 - y1_box1)\n",
    "    # 상자2의 면적 계산\n",
    "    area_box2 = (x2_box2 - x1_box2) * (y2_box2 - y1_box2)\n",
    "\n",
    "    # 상자1과 상자2의 겹치는 영역 계산\n",
    "    x_left = max(x1_box1, x1_box2)\n",
    "    y_top = max(y1_box1, y1_box2)\n",
    "    x_right = min(x2_box1, x2_box2)\n",
    "    y_bottom = min(y2_box1, y2_box2)\n",
    "\n",
    "    # 겹치는 영역의 면적 계산\n",
    "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
    "\n",
    "    # IoU 계산\n",
    "    iou = intersection_area / float(area_box1 + area_box2 - intersection_area)\n",
    "\n",
    "    # IoU가 지정한 임계값 이상인 경우, 더 작은 상자 index를 반환\n",
    "    if iou >= iou_threshold:\n",
    "        if area_box1 < area_box2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e91459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_smaller_box_with_iou_threshold((0, 0, 9, 9), (2, 2, 5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80762fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(\n",
    "            456,\n",
    "            456,\n",
    "            border_mode=0,\n",
    "            value=(0, 0, 0),\n",
    "        ),\n",
    "        # A.RandomBrightnessContrast(p=1),\n",
    "        A.ToGray(p=1),\n",
    "        A.Equalize(by_channels=False, p=1),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c07821",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "import ttach as tta\n",
    "\n",
    "tta_transforms = tta.Compose(\n",
    "    [\n",
    "        # tta.FiveCrops(350, 350),\n",
    "        # tta.Rotate90(angles=[0, 180]),\n",
    "        # tta.Scale(scales=[1, 2, 4]),\n",
    "        # tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "        tta.HorizontalFlip(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    model = create_model(CFG.num_classes)\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "\n",
    "    check_point = torch.load(\n",
    "        f\"{CFG.recorder_dir}/fold_{i}/best_model.pt\",\n",
    "        map_location=device,\n",
    "    )\n",
    "    print(check_point[\"epoch\"])\n",
    "    print(check_point[\"best_score\"])\n",
    "    model.load_state_dict(check_point[\"model\"])\n",
    "    model.eval()\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "    model_list.append(tta_model)\n",
    "\n",
    "# for i in range(0, 5):\n",
    "#     model = create_model(CFG.num_classes)\n",
    "#     model.to(device)\n",
    "#     model.cuda()\n",
    "\n",
    "#     check_point = torch.load(\n",
    "#         f\"{CFG.recorder_dir}/fold_{i}/checkpoint.pt\",\n",
    "#         map_location=device,\n",
    "#     )\n",
    "#     print(check_point[\"epoch\"])\n",
    "#     print(check_point[\"best_score\"])\n",
    "#     model.load_state_dict(check_point[\"model\"])\n",
    "#     model.eval()\n",
    "#     tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "#     model_list.append(tta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904aac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 0  # 656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/*.npy\"))\n",
    "# test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/155231127_0.npy\"))\n",
    "print(test_list[test_index])\n",
    "print(test_index)\n",
    "img = cv2.cvtColor(np.load(test_list[test_index]), cv2.COLOR_BGR2RGB)\n",
    "test_index += 1\n",
    "with torch.no_grad():\n",
    "    print(img.shape)\n",
    "    img = img[5:-5, 5:-5]\n",
    "    test_img = test_transform(image=img)[\"image\"]\n",
    "    test_img = torch.Tensor(test_img).to(device, dtype=torch.float)\n",
    "    test_img = torch.unsqueeze(test_img, 0)\n",
    "    ensemble_probs = None\n",
    "    for tta_model in model_list:\n",
    "        probs = F.softmax(tta_model(test_img), dim=1)\n",
    "        probs = np.round(probs.cpu().detach().numpy(), 3)\n",
    "\n",
    "        if ensemble_probs is None:\n",
    "            ensemble_probs = probs\n",
    "        else:\n",
    "            ensemble_probs = ensemble_probs + probs\n",
    "\n",
    "    ensemble_probs = np.round(ensemble_probs / len(model_list), 3)\n",
    "\n",
    "    top1 = np.max(ensemble_probs)\n",
    "    label = np.argmax(ensemble_probs)\n",
    "    spark_score = ensemble_probs[0][4] + ensemble_probs[0][12] + ensemble_probs[0][23]\n",
    "\n",
    "    gene = ensemble_probs[0][6] + ensemble_probs[0][7]\n",
    "\n",
    "    print(ensemble_probs)\n",
    "    print(top1)\n",
    "    print(f\"spark: {spark_score}\")\n",
    "    print(f\"gene: {gene}\")\n",
    "    print(label)\n",
    "    print(CFG.classes[label])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(tensor2im(test_img[0]))\n",
    "    # f\"{test_path}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_submit = pd.read_csv(\"/data/dacon_cars/data/bbox_submit_npy.csv\")\n",
    "filenames = sorted(os.listdir(\"/data/dacon_cars/data/test\"))\n",
    "\n",
    "total_list = []\n",
    "for target in tqdm(iter(filenames)):\n",
    "    car_info_df = bbox_submit[\n",
    "        (bbox_submit[\"file_name\"] == target)\n",
    "        # & ((bbox_submit[\"point3_x\"] - bbox_submit[\"point1_x\"]) <= 370)\n",
    "        # & ((bbox_submit[\"point3_y\"] - bbox_submit[\"point1_y\"]) <= 441)\n",
    "    ]\n",
    "    # print(one_test)\n",
    "    # if \"064507368\" not in target:\n",
    "    #     continue\n",
    "\n",
    "    infer_list = []\n",
    "    for i, car_info in car_info_df.iterrows():\n",
    "        file_name = car_info[\"file_name\"]\n",
    "\n",
    "        img = cv2.cvtColor(\n",
    "            cv2.imread(f\"/data/dacon_cars/data/test/{file_name}\"),\n",
    "            cv2.COLOR_BGR2RGB,\n",
    "        )\n",
    "        pt1x = int(np.round(car_info[\"point1_x\"])) + 5\n",
    "        pt1y = int(np.round(car_info[\"point1_y\"])) + 5\n",
    "        pt2x = int(np.round(car_info[\"point2_x\"])) - 5\n",
    "        pt2y = int(np.round(car_info[\"point2_y\"])) + 5\n",
    "        pt3x = int(np.round(car_info[\"point3_x\"])) - 5\n",
    "        pt3y = int(np.round(car_info[\"point3_y\"])) - 5\n",
    "        pt4x = int(np.round(car_info[\"point4_x\"])) + 5\n",
    "        pt4y = int(np.round(car_info[\"point4_y\"])) - 5\n",
    "\n",
    "        img = img[pt1y:pt3y, pt1x:pt3x]\n",
    "        with torch.no_grad():\n",
    "            img = test_transform(image=img)[\"image\"]\n",
    "            img = torch.Tensor(img).to(device, dtype=torch.float)\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            ensemble_probs = None\n",
    "            for tta_model in model_list:\n",
    "                probs = F.softmax(tta_model(img), dim=1)\n",
    "                probs = np.round(probs.cpu().detach().numpy(), 3)\n",
    "\n",
    "                if ensemble_probs is None:\n",
    "                    ensemble_probs = probs\n",
    "                else:\n",
    "                    ensemble_probs = ensemble_probs + probs\n",
    "\n",
    "            ensemble_probs = np.round(ensemble_probs / len(model_list), 3)\n",
    "\n",
    "        # for j in range(len(ensemble_probs)):\n",
    "        #     ensemble_probs[j][2] = (\n",
    "        #         ensemble_probs[j][4] + ensemble_probs[j][12] + ensemble_probs[j][23]\n",
    "        #     )\n",
    "        # if \"075817746\" in file_name:\n",
    "        #     print(file_name)\n",
    "        class_id = np.argmax(ensemble_probs)\n",
    "        confidence = ensemble_probs[0][class_id]\n",
    "        spark_score = (\n",
    "            ensemble_probs[0][4] + ensemble_probs[0][12] + ensemble_probs[0][23]\n",
    "        )\n",
    "\n",
    "        infer_list.append(\n",
    "            [\n",
    "                file_name,\n",
    "                class_id,\n",
    "                confidence,\n",
    "                pt1x,\n",
    "                pt1y,\n",
    "                pt2x,\n",
    "                pt2y,\n",
    "                pt3x,\n",
    "                pt3y,\n",
    "                pt4x,\n",
    "                pt4y,\n",
    "                spark_score,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    infer_array = np.array(infer_list)\n",
    "    max_confidence_list = []\n",
    "    try:\n",
    "        # if len(np.where(infer_array.T[2].astype(float) > 0.99)[0]) > 1:\n",
    "        high_confi = np.where(infer_array.T[2].astype(float) >= 0.999)[0]\n",
    "        if len(high_confi) > 1:\n",
    "            print(target)\n",
    "            print(infer_array)\n",
    "\n",
    "            box1 = infer_array[high_confi][0]\n",
    "            box2 = infer_array[high_confi][1]\n",
    "\n",
    "            smaller_index = get_smaller_box_with_iou_threshold(\n",
    "                (int(box1[3]), int(box1[4]), int(box1[7]), int(box1[8])),\n",
    "                (int(box2[3]), int(box2[4]), int(box2[7]), int(box2[8])),\n",
    "            )\n",
    "            print(smaller_index)\n",
    "\n",
    "            if smaller_index is None:  # 안겹침\n",
    "                total_list.append(infer_array[np.argmax(infer_array.T[2])].tolist())\n",
    "                # total_list.append(box1.tolist())\n",
    "                # total_list.append(box2.tolist())\n",
    "            else:\n",
    "                if smaller_index == 0:\n",
    "                    total_list.append(box1.tolist())\n",
    "                else:\n",
    "                    total_list.append(box2.tolist())\n",
    "            continue\n",
    "\n",
    "        top_score = float(infer_array[np.argmax(infer_array.T[2])][2])\n",
    "        if top_score < 0.65:\n",
    "            new_spark = infer_array[np.argmax(infer_array.T[11])].tolist()\n",
    "\n",
    "            if top_score <= float(new_spark[11]):\n",
    "                new_spark[1] = 2\n",
    "                total_list.append(new_spark)\n",
    "                print(target)\n",
    "                print(f\"new_spark!: {new_spark}\")\n",
    "                continue\n",
    "\n",
    "        total_list.append(infer_array[np.argmax(infer_array.T[2])].tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(car_info)\n",
    "\n",
    "    # total_list.append(max_confidence_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e573e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(\n",
    "    total_list,\n",
    "    columns=[\n",
    "        \"file_name\",\n",
    "        \"class_id\",\n",
    "        \"confidence\",\n",
    "        \"point1_x\",\n",
    "        \"point1_y\",\n",
    "        \"point2_x\",\n",
    "        \"point2_y\",\n",
    "        \"point3_x\",\n",
    "        \"point3_y\",\n",
    "        \"point4_x\",\n",
    "        \"point4_y\",\n",
    "        \"spark_score\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# submit_df.astype(\n",
    "#     {\n",
    "#         \"file_name\": \"string\",\n",
    "#         \"class_id\": \"int\",\n",
    "#         \"confidence\": \"float\",\n",
    "#         \"point1_x\": \"float\",\n",
    "#         \"point1_y\": \"float\",\n",
    "#         \"point2_x\": \"float\",\n",
    "#         \"point2_y\": \"float\",\n",
    "#         \"point3_x\": \"float\",\n",
    "#         \"point3_y\": \"float\",\n",
    "#         \"point4_x\": \"float\",\n",
    "#         \"point4_y\": \"float\",\n",
    "#     }\n",
    "# )\n",
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"/data/submit_spark_score_단일_보정_재현1.csv\", index=False)\n",
    "submit_df = pd.read_csv(\"/data/submit_spark_score_단일_보정_재현1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59175332",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(f\"/data/dacon_cars/data/test/134457909.png\")\n",
    "img = img[5:-5, 5:-5]\n",
    "img = cv2.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[(submit_df[\"file_name\"] == \"161544056.png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc585633",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[(submit_df[\"class_id\"] == 2)]  #  & (submit_df[\"confidence\"] < 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd79fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(\"/data/submit_spark_score_단일_보정_재현1.csv\")\n",
    "\n",
    "# data = submit_df[\n",
    "#     (submit_df[\"class_id\"] == 23)\n",
    "#     & (submit_df[\"confidence\"] < 0.999)\n",
    "#     & (submit_df[\"confidence\"] > 0.99)\n",
    "# ].iloc[i]\n",
    "\n",
    "# file_name = data[\"file_name\"]\n",
    "# score = data[\"confidence\"]\n",
    "# i += 1\n",
    "\n",
    "# print(score)\n",
    "# img = cv2.imread(f\"/data/dacon_cars/data/test/{file_name}\")\n",
    "# img = cv2.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(img)\n",
    "\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 12) & (submit_df[\"confidence\"] < 0.65)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 4) & (submit_df[\"confidence\"] < 0.65)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 8) & (submit_df[\"confidence\"] < 0.65)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 22) & (submit_df[\"confidence\"] < 0.65)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 27) & (submit_df[\"confidence\"] < 0.65)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "submit_df.loc[\n",
    "    submit_df[\n",
    "        (submit_df[\"class_id\"] == 23) & (submit_df[\"confidence\"] < 0.99)\n",
    "    ].index.to_list(),\n",
    "    \"class_id\",\n",
    "] = 2\n",
    "\n",
    "\n",
    "# submit_df.loc[\n",
    "#     submit_df[\n",
    "#         (submit_df[\"confidence\"] < 0.7)\n",
    "#         &(submit_df[\"class_id\"] == 4)\n",
    "#         &(submit_df[\"class_id\"] == 8)\n",
    "#         &(submit_df[\"class_id\"] == 11)\n",
    "#         &(submit_df[\"class_id\"] == 15)\n",
    "#         &(submit_df[\"class_id\"] == 20)\n",
    "#         &(submit_df[\"class_id\"] == 27)\n",
    "#         &(submit_df[\"class_id\"] == 33)\n",
    "#     ].index.to_list(),\n",
    "#     \"class_id\",\n",
    "# ] = 2\n",
    "\n",
    "# submit_df.loc[\n",
    "#     submit_df[\n",
    "#         (submit_df[\"confidence\"] < 0.999)\n",
    "#         &(submit_df[\"class_id\"] == 23)\n",
    "#     ].index.to_list(),\n",
    "#     \"class_id\",\n",
    "# ] = 2\n",
    "\n",
    "# 12 빠짐\n",
    "# # 26 < 0.5\n",
    "# # 4, 11, 8, 15, 20, 27, 33 < 0.7\n",
    "# # 23 < 0.99\n",
    "\n",
    "submit_df.to_csv(\"/data/submit_spark_score_단일_보정_재현2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36247de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/*.npy\"))\n",
    "test_list = sorted(glob(\"/data/dacon_cars/data/test_cars/155231127_1.npy\"))\n",
    "print(test_list[test_index])\n",
    "print(test_index)\n",
    "img = cv2.cvtColor(np.load(test_list[test_index]), cv2.COLOR_BGR2RGB)\n",
    "# test_index += 1\n",
    "with torch.no_grad():\n",
    "    print(img.shape)\n",
    "    img = img[5:-5, 5:-5]\n",
    "    test_img = test_transform(image=img)[\"image\"]\n",
    "    test_img = torch.Tensor(test_img).to(device, dtype=torch.float)\n",
    "    test_img = torch.unsqueeze(test_img, 0)\n",
    "    ensemble_probs = None\n",
    "    for tta_model in model_list:\n",
    "        probs = F.softmax(tta_model(test_img), dim=1)\n",
    "        probs = np.round(probs.cpu().detach().numpy(), 3)\n",
    "\n",
    "        if ensemble_probs is None:\n",
    "            ensemble_probs = probs\n",
    "        else:\n",
    "            ensemble_probs = ensemble_probs + probs\n",
    "\n",
    "    ensemble_probs = np.round(ensemble_probs / len(model_list), 3)\n",
    "\n",
    "    top1 = np.max(ensemble_probs)\n",
    "    label = np.argmax(ensemble_probs)\n",
    "    spark_score = ensemble_probs[0][4] + ensemble_probs[0][12] + ensemble_probs[0][23]\n",
    "\n",
    "    gene = ensemble_probs[0][6] + ensemble_probs[0][7]\n",
    "\n",
    "    print(ensemble_probs)\n",
    "    print(top1)\n",
    "    print(f\"spark: {spark_score}\")\n",
    "    print(f\"gene: {gene}\")\n",
    "    print(label)\n",
    "    print(CFG.classes[label])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(tensor2im(test_img[0]))\n",
    "    # f\"{test_path}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(\"/data/submit_special_spark.csv\").iloc[:, 1:]\n",
    "submit_df\n",
    "\n",
    "from src.image_eda.v1 import apply_bbox\n",
    "\n",
    "for i, row in tqdm(submit_df.iterrows()):\n",
    "    img = cv2.imread(f\"/data/dacon_cars/data/test/{row['file_name']}\")\n",
    "\n",
    "    img = apply_bbox(\n",
    "        img,\n",
    "        [row[\"class_id\"] + 1],\n",
    "        [[row[\"point1_x\"], row[\"point1_y\"], row[\"point3_x\"], row[\"point3_y\"]]],\n",
    "        CFG.classes,\n",
    "        [row[\"confidence\"]],\n",
    "        [0, 255, 0],\n",
    "    )\n",
    "\n",
    "    cv2.imwrite(\n",
    "        f\"/data/dacon_cars/data/draw_bbox/{row['file_name'].replace('.png', '.jpg')}\",\n",
    "        img,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for i, row in submit_df[submit_df[\"class_id\"] == 2].iterrows():\n",
    "    shutil.copy(\n",
    "        f\"/data/dacon_cars/data/test_cars_image/{row['file_name'].replace('.png', '_0.png')}\",\n",
    "        f\"/data/dacon_cars/data/export/{row['file_name'].replace('.png', '_0.png')}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.hist(submit_df[\"class_id\"], 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f751ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit2_df = pd.read_csv(\"/data/submit2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat(\n",
    "    [submit_df[\"file_name\"], submit_df[\"class_id\"], submit2_df[\"class_id\"]],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "compare_df = pd.merge(\n",
    "    submit_df[[\"file_name\", \"class_id\"]],\n",
    "    submit2_df[[\"file_name\", \"class_id\"]],\n",
    "    how=\"outer\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    indicator=True,\n",
    ")\n",
    "\n",
    "compare_df.columns = [\"file_name\", \"class_id1\", \"class_id2\"]\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_df.compare(compare_df, align_axis=1))  # index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
